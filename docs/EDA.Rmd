# ---
# knit: (function(input_file, encoding) {
#   out_dir <- 'docs';
#   rmarkdown::render(input_file,  
#     encoding=encoding,
#     output_file=file.path(dirname(input_file), out_dir, 'EDA.md')) })
# output: github_document
# editor_options: 
#   chunk_output_type: console
# ---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, fig.align=TRUE)
options(width=125)
```

# Exploratory Data Analysis

###### Published:

\newline

While we began with a focus on [data cleaning](https://tylerbg.github.io/CDAR/docs/data_cleaning), cleaning and exploratory data analysis (EDA) are two interchangable methods.  This is because we first have to explore our data before we know how to clean it but we also need to clean our data to further explore it.  Thus, you may notice that we actually did some EDA during our data cleaning, and we will also be performing cleaning while we focus on EDA here.

EDA is not some fundamental set of techniques but instead an approach to data analysis.  This is why any one data scientist will employ differenet techniques and have a different philosophy on how to perform EDA.  Here, we will go over multiple approaches and describe the advantages and pitfalls of each.   

```{r}
setwd("~/CDAR")
beer <- read.csv("data/beer_EDA.csv")
```

```{r}
summary(beer)
```

For most of our graphical EDA we will be employing the `ggplot2` package which comes with `tidyverse`.  While we will go over different graphical schemes here, [Data Carpentry](https://datacarpentry.org/R-ecology-lesson/04-visualization-ggplot2.html) and [Harvard](https://tutorials.iq.harvard.edu/R/Rgraphics/Rgraphics.html) have great tutorials starting from basic applications to more advanced plotting to get familiar with `ggplot2`.

```{r}
library(tidyverse)

theme_set(theme_bw())  # this line is not necessary, I tend to prefer this theme
```

One of the more typical and important questions we will have about our data is how is it distributed?  There are many ways to observe the distribution of data, with histograms being one of the popular methods.

```{r}
ggplot(beer, aes(x=abv)) +
  geom_histogram(bins=10, fill="steelblue1", color="steelblue")
```

However, a fallback of using histograms is that the data are stored in 'bins', which can result in the data being very misleading when the bin number is low or difficult to analyze if the bin number is too high.  We used a bin size of 10 above, but what if we change that to 30 or 100?

```{r}
library(gridExtra)

hist1 <- ggplot(beer, aes(x=abv)) +
  geom_histogram(bins=30, fill="steelblue1", color="steelblue")

hist2 <- ggplot(beer, aes(x=abv)) +
  geom_histogram(bins=100, fill="steelblue1", color="steelblue")

grid.arrange(hist1, hist2, ncol=2)
```

Another disadvantage of histograms is that it can be difficult comparing factors within our variable of interest.  For instance, what if we wanted to look at the distribution of ABVs for each of the five breweries?  We could color-code each of the breweries as follows:

```{r}
ggplot(beer, aes(x=abv, fill=brewery, color=brewery)) +
  scale_color_brewer() +
  scale_fill_brewer() +
  geom_histogram(bins=30)
```

However, that is fairly messy and very difficult to get much useful information from.  Another method is to make histograms separately for each brewery.

```{r}
ggplot(beer, aes(x=abv, fill=brewery)) +
  geom_histogram(bins=30) +
  facet_wrap(~brewery, scales="free")
```

While this is much better, it is still difficult to make comparisons between the factors.  For more on designing histograms in `R` with `ggplot2`, [here is a great resource ](http://www.sthda.com/english/wiki/ggplot2-histogram-plot-quick-start-guide-r-software-and-data-visualization).

An alternative to the histogram is the frequency polygon, which is basically a reconstructed histogram using points and lines to represent ferquencies rather than rectangles.  These can also be easily generated using `ggplot2`.

```{r}
ggplot(beer, aes(x=abv, colour=brewery)) +
  geom_freqpoly(binwidth=0.1) +
  theme(legend.position="bottom") +
  guides(colour=guide_legend(nrow=2, byrow=TRUE))
```

The frequency polygon makes it much easier to compare the distributions between our factors compared to the histogram, however it is still not as easy to analyze as other graphical methods.  A second alternative similar to the histogram is the density plot.  

```{r}
library(gridExtra)

plot1 <- ggplot(beer, aes(x=abv)) +
  geom_density()

plot2 <- ggplot(beer, aes(x=abv, colour=brewery)) +
  geom_density() +
  theme(legend.position=c(0.95, 0.95), legend.justification=c("right", "top"))

grid.arrange(plot1, plot2, ncol=2)
```

[Here is a good resource for designing density plots with `ggplot2`. ](http://www.sthda.com/english/wiki/ggplot2-density-plot-quick-start-guide-r-software-and-data-visualization)

Instead, we can use another common graphical approach to observe distributions, box plots.  These types of plots have the advantage of showing the [median, upper and lower quartiles, inter-quartile range, minimum and maximum, variability outside of the quartiles, and outliers all in the same graph](https://towardsdatascience.com/understanding-boxplots-5e2df7bcbd51).  Additionally, it is easier to compare the distributions between factors.

```{r}
box1 <- ggplot(beer, aes(y=abv)) +
  geom_boxplot() +
  coord_flip()

box2 <- ggplot(beer, aes(x=brewery, y=abv, color=brewery)) +
  geom_boxplot() +
  coord_flip()

grid.arrange(box1, box2, nrow=2)
```

We can also plot individual data points on the plots that can help to further observe the distributions.

```{r}
ggplot(beer, aes(x=brewery, y=abv, color=brewery)) +
  geom_boxplot() +
  geom_jitter(shape=16, cex=0.1) +
  coord_flip()
```

With the data points displayed we can clearly see that our data is not continuously distributed as we might expect (do that many beers really have the exact same ABV)?  Of course, this is due to how the ABVs are recorded and reported to be rounded to the nearest 10th.

There are many variations of boxplots to assist in properly observing the underlying distributions, including notched plots:

```{r, warning=FALSE}
ggplot(beer, aes(x=brewery, y=abv, color=brewery)) +
  geom_boxplot(notch=TRUE) +
  theme(legend.position='none') +
  coord_flip()
```

and violin plots:

```{r}
ggplot(beer, aes(x=brewery, y=abv, color=brewery)) +
  geom_violin(trim=FALSE, scale='width') +
  theme(axis.text.x=element_blank()) +
  geom_boxplot(width=0.1)
```

While notch and violin plots provide more information about the underlying distribution, they do not make it any easier to identify the mean on top of being difficult to read, particularly for someone who is unfamiliar with the plot style.  Additionally, we are allowing `ggplot2` to classify our outliers for us, which by default may be too rigid or too lenient.  While we can change how `ggplot2` identifies outliers it is probably best to use other methods to specifically identify and remove them.

For more on designing boxplots with `ggplot2`, [this is a good resource](http://www.sthda.com/english/wiki/ggplot2-box-plot-quick-start-guide-r-software-and-data-visualization) with methods that can also be easily applied to notch and violin plots.



```{r}
ggplot(beer, aes(sample=abv)) +
  geom_qq() +
  geom_qq_line()
```


```{r}
library(ggpubr)

ggqqplot(beer$abv, color="steelblue") +
  theme_bw()

ggqqplot(beer, x="abv", color="brewery", ggtheme = theme_bw())
```






### Categorical Data & Proportions

What if instead we are interested in observing how many reviewers rated the beers from one brewery over another?  

```{r}
ggplot(beer, aes(x=taste, fill=brewery)) +
  geom_bar(position="stack")

ggplot(beer, aes(x=taste, fill=brewery)) +
  geom_bar(position="fill")
```


```{r}
ggplot(beer, aes(x=total, fill=brewery)) +
  geom_bar(position="stack") +
  theme_bw()

ggplot(beer, aes(x=total, fill=brewery)) +
  geom_bar(position="fill") +
  theme_bw()
```

```{r}
barplot(table(beer$overall))
```


```{r}
beer[, c(3,7:11)] %>%
  gather(-brewery, key="var", value="value") %>%
  ggplot(aes(x=value, fill=brewery)) +
  geom_bar(position="stack") +
  facet_wrap(~var, scales="free")

beer[, c(3,7:11)] %>%
  gather(-brewery, key="var", value="value") %>%
  ggplot(aes(x=value, fill=brewery)) +
  geom_bar(position="fill") +
  facet_wrap(~var, scales="free")
```




```{r}
ggplot(beer) +
  geom_count(aes(x=brewery, y=style)) +
  theme_bw()
```

```{r}
plot(beer$time, beer$total)
beer$Date <- as.Date(beer$time)

ggplot(beer, aes(x=Date, y=total)) +
  geom_point(color="slateblue") +
  geom_smooth(method='lm', se=FALSE) +
  theme_bw()
```


```{r}
brewery.lm <- lm(as.numeric(beer$brewery)~abv, beer)
summary(brewery.lm)

anova(brewery.lm)

```

### Time data

While we will go more in-depth on how to work with time series data in future posts, we should go over some basics on how to make some general observations for EDA.

```{r}
average <- ts(beer$average)
plot(average, type='l')
```

```{r}
library(astsa)
lag1.plot(average, 1)
```

```{r}
acf2(average)
```


```{r}
sum(beer$brewery=="Victory Brewing Company")

time.lm <- lm(beer$total[beer$brewery=="Victory Brewing Company"]~seq(1:sum(beer$brewery=="Victory Brewing Company")))
summary(time.lm)

plot(ts(beer$total[beer$brewery=="Victory Brewing Company"]))
abline(lm(beer$total[beer$brewery=="Victory Brewing Company"]~seq(1:sum(beer$brewery=="Victory Brewing Company"))))

plot(ts(beer$total[beer$brewery=="Victory Brewing Company"]))
abline(lm(beer$total[beer$brewery=="Victory Brewing Company"]~seq(1:sum(beer$brewery=="Victory Brewing Company"))))

company.levels <- levels(beer$brewery)
company <- company.levels[5]
plot(ts(beer$total[beer$brewery==company]))
abline(lm(beer$total[beer$brewery==company]~seq(1:sum(beer$brewery==company))), col="red")
time.lm <- lm(beer$total[beer$brewery==company]~seq(1:sum(beer$brewery==company)))
summary(time.lm)
print(company)
```

### Comparing two or more variables

```{r}
ggplot(beer, aes(x=abv, y=total)) +
  geom_density_2d() +
  geom_point()
```

### Other Resources

[What is EDA?](https://www.itl.nist.gov/div898/handbook/eda/section1/eda11.htm)

[Penn State STAT 508: EDA](https://online.stat.psu.edu/stat508/lesson/1b)

[Fundamentals of Data Visualization by Claus O. Wilke](https://serialmentor.com/dataviz/)

[How to Interpret a QQ plot (Stack Exchange)](https://stats.stackexchange.com/questions/101274/how-to-interpret-a-qq-plot)